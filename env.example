PORT=8080
DSN=host=localhost user=deframer password=deframer dbname=deframer port=5432 sslmode=disable
LOG_DATABASE=false
LOG_LEVEL=debug
LOCAL_FEED_FILES_DIR=

BASIC_AUTH_USER=
BASIC_AUTH_PASSWORD=

## LLM (dummy) - default
# LLM_TYPE=dummy

## LLM (gemini)
# LLM_TYPE=gemini
# LLM_MODEL=gemini-2.5-flash-lite #gemini-3-flash-preview
# LLM_API_KEY=SECRET_API_KEY

## LLM (openai)
# LLM_TYPE=openai
# LLM_MODEL=gpt-4o-mini
# LLM_API_KEY=

## LLM (openai api using LM Studio - on Mac Mini M1)
# LLM_TYPE=openai
# LLM_MODEL=meta-llama-3.1-8b-instruct # careful with to small models - they hallucinate a lot
# LLM_API_KEY= # empty or ask your provider
# LLM_BASE_URL=http://mac-mini:1234/v1

## LLM (grok -this is identical to openai)
# LLM_TYPE=openai
# LLM_MODEL=grok-2-latest
# LLM_API_KEY=SECRET_API_KEY
# LLM_BASE_URL=https://api.x.ai/v1

# Docker Compose Configuration
# this is currently (semi) broken - the AI runs are not load balanced - single server / single worker works
# DOCKER_SERVICE_REPLICAS=3
# DOCKER_WORKER_REPLICAS=2

# Caching
DISABLE_ETAG=false
